# AIWalt

A voice-activated AI assistant for **Raspberry Pi 5** â€” inspired by Jarvis and Griot from the Marvel universe. Always listening, always ready.

## How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Wake Word   â”‚â”€â”€â”€â”€â–¶â”‚  Speech to   â”‚â”€â”€â”€â”€â–¶â”‚    Claude     â”‚â”€â”€â”€â”€â–¶â”‚  Text to     â”‚
â”‚  (Porcupine) â”‚     â”‚  Text (Azure)â”‚     â”‚    (Brain)    â”‚     â”‚  Speech(Azure)â”‚
â”‚  ON-DEVICE   â”‚     â”‚              â”‚     â”‚              â”‚     â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     ğŸ¤ Mic              ğŸ¤ â†’ ğŸ“              ğŸ“ â†’ ğŸ§               ğŸ”Š Speaker
```

1. **Wake word detection** â€” Porcupine (Picovoice) listens continuously on-device. No cloud calls, no latency. Default wake word: `"jarvis"`.
2. **Speech-to-Text** â€” Azure Cognitive Services transcribes your voice command.
3. **AI Brain** â€” Claude (Anthropic) processes the transcription with conversational memory.
4. **Text-to-Speech** â€” Azure synthesizes the response and plays it through your speaker.

## Prerequisites

### Hardware
- Raspberry Pi 5 (4GB+ RAM recommended)
- USB microphone or a HAT with mic (e.g., ReSpeaker)
- Speaker (3.5mm, Bluetooth, or USB)
- Internet connection (for Azure + Claude APIs)

### API Keys (3 required)
| Service | Purpose | Get it at |
|---------|---------|-----------|
| **Picovoice** | Wake word detection | https://console.picovoice.ai/ |
| **Azure Speech** | STT + TTS | https://portal.azure.com/ â†’ Cognitive Services â†’ Speech |
| **Anthropic** | AI conversation | https://console.anthropic.com/ |

## Quick Start

### 1. Clone and set up

```bash
git clone <this-repo> ~/aiwalt
cd ~/aiwalt
chmod +x scripts/setup-pi.sh
./scripts/setup-pi.sh
```

The setup script installs system dependencies, creates a Python virtual environment, and installs the package.

### 2. Configure API keys

```bash
cp config/.env.example .env
nano .env   # fill in your 3 API keys
```

### 3. Test components individually

```bash
source .venv/bin/activate

# List audio devices (verify your mic is detected)
aiwalt --list-devices

# Test text-to-speech
aiwalt --test-tts "Hello, I am Griot. Your AI assistant is online."

# Test speech-to-text (speak after running)
aiwalt --test-stt
```

### 4. Run the assistant

```bash
aiwalt
```

Say **"Jarvis"** (or your configured wake word), then speak your command.

## Run as a 24/7 Service

```bash
# Copy the systemd unit (edit paths in the file if your user isn't 'pi')
sudo cp scripts/aiwalt.service /etc/systemd/system/
sudo systemctl daemon-reload
sudo systemctl enable --now aiwalt

# View logs
journalctl -u aiwalt -f
```

## Configuration

All settings are configured via environment variables (`.env` file):

| Variable | Default | Description |
|----------|---------|-------------|
| `AZURE_SPEECH_KEY` | *(required)* | Azure Speech Services key |
| `AZURE_SPEECH_REGION` | `eastus` | Azure region |
| `ANTHROPIC_API_KEY` | *(required)* | Anthropic API key |
| `PICOVOICE_ACCESS_KEY` | *(required)* | Picovoice access key |
| `ASSISTANT_NAME` | `Griot` | Name used in the system prompt |
| `WAKE_WORD` | `jarvis` | Porcupine built-in keyword |
| `VOICE_NAME` | `en-US-GuyNeural` | Azure TTS voice |
| `SILENCE_TIMEOUT_MS` | `1500` | Silence before ending speech capture |
| `CONVERSATION_HISTORY_LIMIT` | `20` | Max conversation pairs to remember |
| `CLAUDE_MODEL` | `claude-sonnet-4-20250514` | Claude model identifier |

### Available Wake Words (built-in)

`alexa`, `bumblebee`, `computer`, `hey google`, `hey siri`, `jarvis`, `ok google`, `porcupine`, `terminator`

### Recommended Azure TTS Voices

- `en-US-GuyNeural` â€” deep, confident male voice (Jarvis-like)
- `en-US-DavisNeural` â€” warm, authoritative male voice
- `en-US-JennyNeural` â€” clear female voice (Friday-like)
- `en-US-AriaNeural` â€” expressive female voice

## Voice Commands

- Say the **wake word** to activate, then speak naturally
- Say **"goodbye"** / **"shut down"** to stop the assistant
- Say **"reset conversation"** / **"start over"** to clear chat history

## Project Structure

```
aiwalt/
â”œâ”€â”€ aiwalt/
â”‚   â”œâ”€â”€ main.py              # CLI entry point
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py         # Settings (pydantic-settings)
â”‚   â”‚   â””â”€â”€ assistant.py      # Main orchestrator
â”‚   â”œâ”€â”€ audio/
â”‚   â”‚   â””â”€â”€ wake_word.py      # Porcupine wake word detector
â”‚   â”œâ”€â”€ speech/
â”‚   â”‚   â”œâ”€â”€ stt.py            # Azure Speech-to-Text
â”‚   â”‚   â””â”€â”€ tts.py            # Azure Text-to-Speech
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â””â”€â”€ brain.py          # Claude conversation engine
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ logger.py         # Logging setup
â”œâ”€â”€ config/
â”‚   â””â”€â”€ .env.example          # Template for API keys
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup-pi.sh           # One-time Pi setup
â”‚   â””â”€â”€ aiwalt.service        # systemd unit file
â”œâ”€â”€ tests/
â”œâ”€â”€ pyproject.toml
â””â”€â”€ requirements.txt
```

## Troubleshooting

**No audio devices found**: Make sure your USB mic is plugged in. Run `arecord -l` and `aplay -l` to verify. You may need to set the default device in `/etc/asound.conf` or PulseAudio config.

**Wake word not triggering**: Try increasing sensitivity by modifying `WakeWordDetector(sensitivity=0.7)` or running in a quieter environment.

**Azure STT returns no match**: Check your Azure key/region, and ensure the mic is picking up audio (`arecord -d 3 test.wav && aplay test.wav`).

**Service won't start**: Check `journalctl -u aiwalt -e` for errors. Ensure the `.env` file is readable and paths in `aiwalt.service` match your setup.
